{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenVINO Local Pipelines with HuggingFace\n",
    "\n",
    "https://python.langchain.com/docs/integrations/llms/openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade-strategy eager \"optimum[openvino,nncf]\" --quiet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authorization token already provided\n"
     ]
    }
   ],
   "source": [
    "## login to huggingfacehub to get access to pretrained model \n",
    "\n",
    "from huggingface_hub import notebook_login, whoami\n",
    "\n",
    "try:\n",
    "    whoami()\n",
    "    print('Authorization token already provided')\n",
    "except OSError:\n",
    "    notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1356f185025e4d90a7c99ae9c659f4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc33838bf7f4cf0bbe1f885f076a914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9177c90c4d894052a8ccfb8dedb3075a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e01974538224414bd30b5645f66cffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5601962a42cc4660ae0509935cdb90e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, onnx, openvino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Framework not specified. Using pt to export the model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88d9e733aa74befa232adb9469c699f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccc0911def442f19d6e3b2111f520cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the export variant default. Available variants are:\n",
      "    - default: The default ONNX variant.\n",
      "Using framework PyTorch: 2.2.2+cpu\n",
      "The BetterTransformer implementation does not support padding during training, as the fused kernels do not support attention masks. Beware that passing padded batched data during training may result in unexpected outputs. Please refer to https://huggingface.co/docs/optimum/bettertransformer/overview for more details.\n",
      "Overriding 1 configuration item(s)\n",
      "\t- use_cache -> True\n",
      "c:\\workspace\\llm\\.venv\\lib\\site-packages\\transformers\\modeling_utils.py:4193: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n",
      "c:\\workspace\\llm\\.venv\\lib\\site-packages\\transformers\\models\\gpt2\\modeling_gpt2.py:801: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size <= 0:\n",
      "c:\\workspace\\llm\\.venv\\lib\\site-packages\\optimum\\bettertransformer\\models\\attention.py:52: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size == 1 and attention_mask is not None and attention_mask[0, 0, -1, -1] < -1:\n",
      "c:\\workspace\\llm\\.venv\\lib\\site-packages\\optimum\\bettertransformer\\models\\attention.py:56: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if batch_size == 1 or self.training:\n",
      "c:\\workspace\\llm\\.venv\\lib\\site-packages\\optimum\\bettertransformer\\models\\attention.py:70: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if query_length > 1:\n",
      "Compiling the model to GPU ...\n",
      "Exception ignored in: <finalize object at 0x275b8a71ee0; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python39\\lib\\weakref.py\", line 591, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"C:\\Python39\\lib\\tempfile.py\", line 820, in _cleanup\n",
      "    cls._rmtree(name)\n",
      "  File \"C:\\Python39\\lib\\tempfile.py\", line 816, in _rmtree\n",
      "    _shutil.rmtree(name, onerror=onerror)\n",
      "  File \"C:\\Python39\\lib\\shutil.py\", line 759, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Python39\\lib\\shutil.py\", line 629, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"C:\\Python39\\lib\\tempfile.py\", line 808, in onerror\n",
      "    cls._rmtree(path)\n",
      "  File \"C:\\Python39\\lib\\tempfile.py\", line 816, in _rmtree\n",
      "    _shutil.rmtree(name, onerror=onerror)\n",
      "  File \"C:\\Python39\\lib\\shutil.py\", line 759, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "  File \"C:\\Python39\\lib\\shutil.py\", line 610, in _rmtree_unsafe\n",
      "    onerror(os.scandir, path, sys.exc_info())\n",
      "  File \"C:\\Python39\\lib\\shutil.py\", line 607, in _rmtree_unsafe\n",
      "    with os.scandir(path) as scandir_it:\n",
      "NotADirectoryError: [WinError 267] The directory name is invalid: 'C:\\\\Users\\\\test1\\\\AppData\\\\Local\\\\Temp\\\\tmpkh2sh5kz\\\\openvino_model.bin'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "ov_config = {\"PERFORMANCE_HINT\": \"LATENCY\", \"NUM_STREAMS\": \"1\", \"CACHE_DIR\": \"\"}\n",
    "\n",
    "ov_llm = HuggingFacePipeline.from_model_id(\n",
    "    #model_id=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    model_id=\"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    backend=\"openvino\",\n",
    "    model_kwargs={\"device\": \"GPU\", \"ov_config\": ov_config},\n",
    "    pipeline_kwargs={\"max_new_tokens\": 512},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Question: what do you like?\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " 'The main character is pretty good, but his appearance is very off center so '\n",
      " 'I would advise him not to speak very much, but if you want to be honest the '\n",
      " 'main character speaks with a little more calm demeanor...')\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | ov_llm\n",
    "\n",
    "question = \"i can fly and i can swim, what am i?\"\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(chain.invoke({\"question\": question}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

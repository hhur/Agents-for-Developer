{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to access the openAI API, you need an API key which you can get it from  https://platform.openai.com/api-keys\n",
    "once you have a key then you can either save it as an environment variable or hard code in as needed from simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"your key\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model_name=\"gpt-4-0125-preview\")\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also load directory using directory loader.\n",
    "and split a long document into smaller chunks that can fit into your model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_community.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain_community.document_loaders.xml import UnstructuredXMLLoader\n",
    "from langchain_community.document_loaders.markdown import UnstructuredMarkdownLoader\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# define a dictionary to map file extensions to document loaders\n",
    "document_loaders = {\n",
    "    \"txt\": TextLoader,\n",
    "    \"pdf\": PyMuPDFLoader,\n",
    "    \"xml\": UnstructuredXMLLoader,\n",
    "    \"md\": UnstructuredMarkdownLoader,\n",
    "    \"csv\": CSVLoader\n",
    "}\n",
    "\n",
    "# define function to create DirectroyLoader for file type\n",
    "def create_directory_loader(file_type, path):\n",
    "    loader_cls = document_loaders.get(file_type)\n",
    "    if loader_cls is None:\n",
    "        raise ValueError(f\"Unsupported file type: {file_type}\")\n",
    "    return DirectoryLoader(path, glob=f\"*.{file_type}\", loader_cls=loader_cls)\n",
    "\n",
    "# create characterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    "all_documents = []\n",
    "\n",
    "# loop each file type and create DirectoryLoader\n",
    "for file_type in document_loaders.keys():\n",
    "    loader = create_directory_loader(file_type, f\"../article\")\n",
    "    raw_documents = loader.load()\n",
    "    documents = text_splitter.split_documents(raw_documents)\n",
    "    all_documents.extend(documents)\n",
    "\n",
    "\n",
    "#len(raw_documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "search result will be fetched by retriever and it'll be used as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "vectorstore = FAISS.from_documents(all_documents, embedding=OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"]))\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invoke question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Based on the provided context, FunnyIO seems to be a fictional '\n",
      " 'high-performance and scalable host controller interface designed for '\n",
      " 'accessing solid-state drives (SSDs) over a PCI Express (PCIe) bus. The '\n",
      " 'development of FunnyIO drivers is crucial for enabling efficient '\n",
      " 'communication between the operating system and FunnyIO storage devices. Here '\n",
      " 'are some key aspects and best practices in FunnyIO driver development as '\n",
      " 'gathered from the documents:\\n'\n",
      " '\\n'\n",
      " '1. **FunnyIO Protocol**: This protocol is tailored to exploit the low '\n",
      " 'latency and parallelism of modern SSDs. It includes efficient mechanisms for '\n",
      " 'command submission and completion, enabling high-speed data transfers '\n",
      " 'between the host and the storage device.\\n'\n",
      " '\\n'\n",
      " '2. **PCIe Interface**: FunnyIO driver development requires a good '\n",
      " 'understanding of the PCIe bus architecture and communication protocols, as '\n",
      " 'FunnyIO storage devices communicate over this interface.\\n'\n",
      " '\\n'\n",
      " '3. **Memory Management**: Effective memory resource management is essential '\n",
      " 'for optimizing data transfers and maintaining system stability and '\n",
      " 'performance. This involves proper memory allocation and deallocation '\n",
      " 'strategies.\\n'\n",
      " '\\n'\n",
      " '4. **Command Queues**: FunnyIO drivers use command queues to submit and '\n",
      " 'process I/O commands to the storage device. Developing efficient command '\n",
      " 'queue management algorithms is crucial for enhancing the performance of '\n",
      " 'FunnyIO storage systems.\\n'\n",
      " '\\n'\n",
      " '5. **Error Handling**: The reliability and robustness of FunnyIO drivers '\n",
      " 'depend on graceful error and exception handling. Implementing error recovery '\n",
      " 'mechanisms and logging can aid in diagnosing and resolving issues.\\n'\n",
      " '\\n'\n",
      " '6. **Performance Optimization**: Techniques such as asynchronous I/O '\n",
      " 'operations, interrupt handling, and caching are employed to optimize data '\n",
      " 'transfer speeds, reduce latency, and minimize CPU overhead.\\n'\n",
      " '\\n'\n",
      " 'Developers aiming to create efficient and reliable FunnyIO drivers must have '\n",
      " 'a deep understanding of these aspects, along with the FunnyIO protocol, PCIe '\n",
      " 'interface, memory management, command queues, error handling, and '\n",
      " 'performance optimization techniques. By adhering to best practices in '\n",
      " 'FunnyIO driver development, developers can facilitate high-speed data '\n",
      " 'transfers between the host and FunnyIO storage devices. Further insights and '\n",
      " 'updates on FunnyIO driver development are expected to be shared in future '\n",
      " 'articles, hinting at an ongoing exploration of this technology.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | model \n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"tell me about funnnnyIO\"))\n",
    "#pprint(chain.invoke(\"what is ramda AI?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OLLAMA\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# check if USE_OLLAMA is True\n",
    "if os.getenv('USE_OLLAMA') == 'True':\n",
    "    print('Using OLLAMA')\n",
    "if os.getenv('USE_OPENAI') == 'True':\n",
    "    print('Using OpenAI') \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "#model = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model_name=\"gpt-4-0125-preview\")\n",
    "model = ChatOllama(model=\"llama2\")\n",
    "\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use document loaders to load data from a source as Document\n",
    "\n",
    "Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "search result will be fetched by retriever and it'll be used as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\python39\\lib\\site-packages (4.0.2)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.3 in c:\\python39\\lib\\site-packages (from pypdf) (4.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also load directory using directory loader.\n",
    "and split a long document into smaller chunks that can fit into your model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "raw_documents = DirectoryLoader('../article', glob=\"*.pdf\", loader_cls=PyPDFLoader).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "search result will be fetched by retriever and it'll be used as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "\n",
    "#vectorstore = FAISS.from_documents(documents, embedding=OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"]))\n",
    "vectorstore = FAISS.from_documents(documents, embedding=GPT4AllEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invoke question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Sure, I'd be happy to help you with information about NVMe!\\n\"\n",
      " '\\n'\n",
      " 'NVMe (Non-Volatile Memory Express) is a protocol for accessing non-volatile '\n",
      " 'memory devices, such as solid-state drives (SSDs), using a PCIe interface. '\n",
      " 'It was developed by a consortium of companies including Intel, Micron '\n",
      " 'Technology, Samsung, and Seagate, among others.\\n'\n",
      " '\\n'\n",
      " 'Here are some key features and aspects of the NVMe protocol:\\n'\n",
      " '\\n'\n",
      " '1. Fast performance: NVMe is designed to provide much faster performance '\n",
      " 'than traditional AHCI (Advanced Host Controller Interface) or IDE '\n",
      " 'interfaces. It uses a specialized controller and a high-speed interface to '\n",
      " 'transfer data directly between the host and the SSD, bypassing the '\n",
      " 'traditional disk access layers.\\n'\n",
      " '2. Low latency: NVMe has lower latency compared to traditional disk '\n",
      " 'interfaces, which means that it can handle requests for data much more '\n",
      " 'quickly. This is particularly important for applications that require '\n",
      " 'frequent access to data, such as video editing or gaming.\\n'\n",
      " '3. Queue depth and command set: NVMe supports a larger queue depth than '\n",
      " 'traditional disk interfaces, which allows it to handle more simultaneous '\n",
      " 'commands. It also has a specialized command set that includes features such '\n",
      " 'as zero-downtime snapshotting and cloning, which are not available on '\n",
      " 'traditional disk interfaces.\\n'\n",
      " '4. Namespaces and NSIDs: NVMe supports the concept of namespaces, which '\n",
      " 'allow multiple independent namespaces to share the same physical device. '\n",
      " 'Each namespace has its own unique identifier (NSID), which can be used to '\n",
      " 'identify and manage data within that namespace.\\n'\n",
      " '5. Endurance and power management: NVMe provides features for managing '\n",
      " 'endurance and power consumption in SSDs, such as power-saving modes and wear '\n",
      " 'leveling. These features help to extend the life of the SSD and improve its '\n",
      " 'overall performance.\\n'\n",
      " '6. Telemetry and log support: NVMe provides support for telemetry logging '\n",
      " 'and firmware commit, which allow for remote monitoring and management of '\n",
      " 'SSDs in a data center environment. It also supports SMART/Health critical '\n",
      " 'warnings, which provide alerts when certain thresholds are reached.\\n'\n",
      " '7. Security features: NVMe includes security features such as secure erase '\n",
      " 'and encryption, which help to protect data stored on SSDs from unauthorized '\n",
      " 'access.\\n'\n",
      " '\\n'\n",
      " 'In summary, NVMe is a high-performance protocol for accessing non-volatile '\n",
      " 'memory devices using a PCIe interface. It provides faster performance, lower '\n",
      " 'latency, and specialized features such as queue depth and command set, '\n",
      " 'namespaces and NSIDs, endurance and power management, telemetry and log '\n",
      " 'support, and security features.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | model \n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"tell me about NVMe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'tell me about NVMe command set', 'result': 'The NVMe command set is a standardized set of commands for interacting with NVMe devices, such as solid-state drives (SSDs) and other non-volatile memory devices. The command set is defined by the NVM Express specification, which provides a common language for device manufacturers and operating systems to communicate with NVMe devices.\\n\\nThe NVMe command set includes several categories of commands:\\n\\n1. Admin Commands: These commands are used for managing the NVMe device, such as setting configuration options, monitoring device status, and performing maintenance tasks. Examples of admin commands include \"Get LBA Status\" and \"Sanitize\".\\n2. I/O Command Set Specific Admin Commands: These commands are specific to a particular I/O command set, such as NVMe over PCIe or NVMe over Fabrics. Examples of these commands include \"Format NVM\" and \"Security Send\".\\n3. Security Commands: These commands are used for securing the NVMe device, such as encrypting data and authenticating users. Examples of security commands include \"Security Send\" and \"Security Receive\".\\n4. Get LBA Status Command: This command is used to retrieve information about the logical block address (LBA) status of the NVMe device.\\n\\nThe NVMe command set is designed to provide a consistent and efficient way for operating systems and applications to interact with NVMe devices, improving performance and reducing overhead compared to traditional storage interfaces.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    model,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")\n",
    "\n",
    "result = qa_chain.invoke({\"query\": \"tell me about NVMe command set\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import os\n",
    "os.environ[\"OPEN_API_KEY\"] = \"your key\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def build(commit_id: int):\n",
    "    \"\"\"build artifact with commit_id .\"\"\"\n",
    "    print(f\"Building artifact with commit_id {commit_id}\")\n",
    "    return \n",
    "\n",
    "@tool\n",
    "def deploy(build_id: int):\n",
    "    \"\"\"deploy artifact with build_id. \"\"\"\n",
    "    print(f\"Deploying artifact with build_id {build_id}\")\n",
    "    return \n",
    "\n",
    "@tool\n",
    "def test(deploy_id: int):\n",
    "    \"test artifact with deploy_id.\"\n",
    "    print(f\"Testing artifact with deploy_id {deploy_id}\")\n",
    "    return \n",
    "\n",
    "#build.invoke({\"commit_id\": 1})\n",
    "\n",
    "from operator import itemgetter\n",
    "from typing import Union\n",
    "\n",
    "from langchain.output_parsers import JsonOutputToolsParser\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=os.environ[\"OPEN_API_KEY\"], model_name=\"gpt-4-0125-preview\")\n",
    "\n",
    "tools = [build, deploy, test]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "# Get the prompt to use \n",
    "# https://github.com/hwchase17/langchain-hub?tab=readme-ov-file\n",
    "#prompt = load_prompt('lc://prompts/conversation/prompt.json')\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"chat_history\",optional=True\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(\n",
    "            variable_name=\"agent_scratchpad\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "prompt.messages\n",
    "#prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = create_openai_tools_agent(model, tools, prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"ninety divided by three, multiply by the sum of twelve and three, then square the whole result\"\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

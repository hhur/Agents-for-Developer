{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to access the openAI API, you need an API key which you can get it from  https://platform.openai.com/api-keys\n",
    "once you have a key then you can either save it as an environment variable or hard code in as needed from simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"your key\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model = ChatOpenAI(openai_api_key=os.environ[\"OPENAI_API_KEY\"], model_name=\"gpt-4-0125-preview\")\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use document loaders to load data from a source as Document\n",
    "\n",
    "Facebook AI Similarity Search (Faiss) is a library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "search result will be fetched by retriever and it'll be used as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import os\n",
    "\n",
    "raw_documents = TextLoader('../article/funnyIO_development.md').load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents, embedding=OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"]))\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | model \n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"tell me about the funnyIO\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can also load directory using directory loader.\n",
    "and split a long document into smaller chunks that can fit into your model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error loading file ..\\article\\emerging_high_speed_io.md\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unstructured package not found, please install it with `pip install unstructured`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\langchain_community\\document_loaders\\unstructured.py:48\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.__init__\u001b[1;34m(self, mode, post_processors, **unstructured_kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'unstructured'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#raw_documents = DirectoryLoader('../article', glob=\"*.py\", loader_cls=PythonLoader).load()\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#raw_documents = DirectoryLoader('../article', glob=\"*.txt\", loader_cls=TextLoader).load()\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m raw_documents \u001b[38;5;241m=\u001b[39m \u001b[43mDirectoryLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../article\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*.md\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUnstructuredMarkdownLoader\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m documents \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(raw_documents)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:194\u001b[0m, in \u001b[0;36mDirectoryLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m items:\n\u001b[1;32m--> 194\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pbar:\n\u001b[0;32m    197\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:137\u001b[0m, in \u001b[0;36mDirectoryLoader.load_file\u001b[1;34m(self, item, path, docs, pbar)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 137\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pbar:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\langchain_community\\document_loaders\\directory.py:130\u001b[0m, in \u001b[0;36mDirectoryLoader.load_file\u001b[1;34m(self, item, path, docs, pbar)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(item)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 130\u001b[0m     sub_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_cls(\u001b[38;5;28mstr\u001b[39m(item), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_kwargs)\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m    131\u001b[0m     docs\u001b[38;5;241m.\u001b[39mextend(sub_docs)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\langchain_community\\document_loaders\\unstructured.py:168\u001b[0m, in \u001b[0;36mUnstructuredFileLoader.__init__\u001b[1;34m(self, file_path, mode, **unstructured_kwargs)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with file path.\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path \u001b[38;5;241m=\u001b[39m file_path\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munstructured_kwargs)\n",
      "File \u001b[1;32mc:\\Python39\\lib\\site-packages\\langchain_community\\document_loaders\\unstructured.py:50\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.__init__\u001b[1;34m(self, mode, post_processors, **unstructured_kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munstructured package not found, please install it with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     52\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install unstructured`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     53\u001b[0m     )\n\u001b[0;32m     54\u001b[0m _valid_modes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpaged\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _valid_modes:\n",
      "\u001b[1;31mValueError\u001b[0m: unstructured package not found, please install it with `pip install unstructured`"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PythonLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "#raw_documents = DirectoryLoader('../article', glob=\"*.py\", loader_cls=PythonLoader).load()\n",
    "#raw_documents = DirectoryLoader('../article', glob=\"*.txt\", loader_cls=TextLoader).load()\n",
    "raw_documents = DirectoryLoader('../article', glob=\"*.md\", loader_cls=UnstructuredMarkdownLoader).load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents, embedding=OpenAIEmbeddings(openai_api_key=os.environ[\"OPENAI_API_KEY\"]))\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "invoke question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Emerging FunnyIO technologies are at the forefront of revolutionizing data '\n",
      " 'transfer and processing across various computing environments. Among these '\n",
      " 'advanced connectivity standards, notable mentions include USB4, Thunderbolt '\n",
      " '4, PCIe 5.0, and FunnyIO 6.0. These technologies are critical for meeting '\n",
      " 'the increasing demands of modern computing by offering high-speed I/O '\n",
      " 'capabilities.\\n'\n",
      " '\\n'\n",
      " 'USB4, in particular, is highlighted as a highly anticipated development in '\n",
      " 'the realm of high-speed I/O technologies. It represents the latest iteration '\n",
      " 'of the Universal Serial Bus standard and boasts substantial improvements in '\n",
      " 'data transfer speeds, with capabilities reaching up to 40 Gbps over a single '\n",
      " 'cable. This enhancement is significant for a variety of applications, '\n",
      " 'including connecting external storage devices, displays, and other '\n",
      " 'peripherals that demand high bandwidth. For users dealing with large volumes '\n",
      " 'of data, USB4 facilitates faster backup and file transfer speeds, thereby '\n",
      " 'boosting productivity.\\n'\n",
      " '\\n'\n",
      " 'The advancements in FunnyIO technologies such as USB4, Thunderbolt 4, PCIe '\n",
      " '5.0, and FunnyIO 6.0 are essential for propelling productivity, streamlining '\n",
      " 'workflows, and unlocking new possibilities in data exchange. These '\n",
      " 'technologies are set to play a crucial role in the evolution of high-speed '\n",
      " 'I/O solutions as they continue to develop, promising to enhance the '\n",
      " 'capabilities of organizations and individuals in managing data more '\n",
      " 'efficiently.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt \n",
    "    | model \n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "pprint(chain.invoke(\"tell me about the emerging funnnnyIO\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
